---
title: "Project 1: Project STAR I"
date: "01/17/2020"
output:
  html_document:
    number_sections: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Group Partners:

1. Bingdao Chen bdchen@ucdavis.edu contribution: 

2. Yahui Li yhuli@ucdavis.edu contribution: 

3. Zihan Wang zihwang@ucdavis.edu contribution: 

4. Jian Shi jnshi@ucdavis.edu contribution: 

# Introduction

This Document is the first project of Group 7 in STA 207, Winter Quarter 2020.

## Background

Tennesses Student/Teacher Achievement Ratio study (Project STAR) was conducted in the late 1980s to evaluate the effect of class size on test scores. The study randomly assigned students to small classes, regular classes, and regular classes with a teacher’s aide. In order to randomize properly, schools were enrolled only if they had enough studybody to have at least one class of each type. Once the schools were enrolled, students were randomly assigned to the three types of classes, and one teacher was randomly assigned to one class.

## Data Description

The `STAR` dataset from the `AER` package which are from the very influential randomized experient STAR, assessing the effect of reducing class size on test scores in the early grades. The dataset contains scaled scores for math and reading from kindergarten to 3rd grade. We will only examine the math scores in 1st grade in this project[1].


The following is the description of `STAR` from [2].

STAR is a data frame containing 11,598 observations on 47 variables.

Here are main variables for 1st grade.


|     Variable      |                                 Description                |
| ---------|:--------------------------------------------------------------------------:|
| `gender`     | factor indicating student's gender. |
| `ethnicity`      | factor indicating student's ethnicity with levels `cauc` (Caucasian), `afam` (African-American), `asian` (Asian), `hispanic` (Hispanic), `amindian` (American-Indian) or `other`. |
| `birth` | student's birth quarter (of class yearqtr). |
| `star1` | factor indicating the STAR class type in 1st grade: `regular`, `small`, or `regular-with-aide`. `NA` indicates that no STAR class was attended. |
| `read1` | total reading scaled score in 1st grade. |
| `math1` | total math scaled score in 1st grade. |
| `lunch1` | factor indicating whether the student qualified for free lunch in 1st grade.|
| `school1` | factor indicating school type in 1st grade: `inner-city`, `suburban`, `rural` or `urban`. |
| `degree1` | factor indicating highest degree of 1st grade teacher: `bachelor`, `master`, `specialist`, or `phd`. |
| `ladder1` | factor indicating teacher's career ladder level in 1st grade: `level1`, `level2`, `level3`, `apprentice`, `probation` or `noladder`. |
| `experience1` | years of teacher's total teaching experience in 1st grade. |
| `tethnicity1` | factor indicating teacher's ethnicity in 1st grade with levels `cauc` (Caucasian) or `afam` (African-American). |
| `system1` | factor indicating school system ID in 1st grade. |
| `schoolid1` | factor indicating school ID in 1st grade. |

### Question of Interest

Our questions have three parts:

a. How to build a one-way ANOVA model to study the effects of class types on the math scaled scores in 1st grade? Is this model appropriate? How does the model fit the data?

b. Is there any difference in the math scaled score in 1st grade across students in different class types?

c. Can we make any causal statements based on the analysis?


# Methods and Results

## Explore Data

We choose two columns `star1` and `math1` in `STAR` as our dataset.

### Deal with NA

The data has several `NA` in both `star1` and `math1`. The `NA` in `star1` means that no STAR class was attended. We checked when `star1` is `NA`, `math1` is also `NA`, which is not informative. Therefore, we removed the cases where `star1` is `NA`.

After that, there are only 229 `NA` in 6829 math scores in `math1`, which have little influence. So we decided to remove them too.

### Summary Statistics

From the pie chart on `star1`, there are almost the same number of cases in different type of classes.

From the box plot on `math1` divided by `star1`, we can see roughly that the quantile of math scores in small class is higher than in regular-with-aide class, which is higher than in regular class. So does the average math score from the summary table.


## One-Way ANOVA

In this part our goal is to build a one-way ANOVA model on `math1` by `star1`.
The model equation and notation as below:

$$Y_{ij} = \mu_{1} + \tau_{2}X_{2,ij} +\tau_{3}X_{3,ij}+\epsilon_{ij},\quad
\epsilon_{ij}\sim\mathrm{N}(0,\sigma^{2}),\quad
i=1,2,3,j=1,\cdots,n_{i}.$$

where $i=1$ means the class type in 1st grade is regular; $i=2$ means the class type in 1st grade is small; $i=3$ means the class type in 1st grade is regular-with-aide.

$n_{1} = 2507, n_{2} = 1868, n_{3} = 2225, n = 6600$.

$X_{2,ij} = 1$ if $i=2$, otherwise $X_{2,ij} = 0$.
$X_{3,ij} = 1$ if $i=3$, otherwise $X_{3,ij} = 0$.

$Y_{ij}$ denotes the math score in 1st grade of the j-th experimental unit
in the i-th class type, $i = 1,2, 3, j = 1,\cdots,n_{i}$.

$\mu_{i}$ means the population mean of math score in i-th type class in 1st grade, $i = 1, 2, 3$.

$\tau_{i} = \mu_{i} - \mu_{1}$ means the difference in population mean of math score between i-th type and first type in 1st grade, $i = 2, 3$.

$\epsilon_{ij}$ is independent and identically distributed normal random variable with $0$ mean and $\sigma^{2}$ variance. 

Model Assumption:

(a) Response variable residuals are normally distributed.  

(b) Variances of populations are equal.  

(c) Responses for a given group are independent and identically distributed normal random variables.  

All of the assumptions are necessary, because F-test and related procedures are pretty robust to the normality and equal variance assumptions, and pairwise comparisons could be substantially affected by unequal variances. Moreover, non-independence can have serious side effects and is hard to correct. So it is important to apply randomization whenever necessary. 

### Box-Cox Transformation

Before we fit the model, we need to ensure that model is appropriate on this dataset, that is, the response variable satisfies the assumptions of our model. In other words, we will check the normality and equal variance of the response varibales.

We first draw the density plot and Q-Q plot to check the normality of `math1` ,and we find the distribution of `math1` is right-skewed. So we use Box-Cox method on `math1` and from the result, we need to make a log-transformation on `math1`. 

After the logarithmic transformation, the distribution shows more normal-like. Then we calculate the variance of log math grade in 1st grade of each class type. The result shows that they are very small and nearly equal to each other. Therefore, it is appropiate to build our model on this dataset after log-transformation on `math1`.

### Fitted Model

From the result in R, the fitted model we get is:
$$\log\hat{Y}_{ij} = 6.2608 + 0.0250 X_{2,ij} + 0.0081X_{3,ij}$$

with means when the type is regular, the estimate math score is $e^{6.2608} = 523.6377$;
when the type is small, the estimate math score is $e^{6.2608+0.0250} = 536.8936$;
when the type is regular-with-aide, the estimate math score is $e^{6.2608+0.0081} = 527.8964$.

The following is a ANOVA table for this model.  

|     Source of Variation   |  Sum of Squares   |  Degrees of Freedom | Mean of Squares | F*|
| --------------|:-----------:|:----------------:|:------------------------------------------:| :-----:|
| `Between treatments`     | SSTR = 0.68 | 2  |  MSTR = 0.3391  |  F* = 52.56 |
| `Within treatments`      | SSE = 42.55 | 6597 |   MSE = 0.0065  | | |
|    `Total`      |   SSTO = 43.23  |  6599   |       |     | |

The null hypothesis is $\tau_{2} = \tau_{3} = 0$, and the alternative hypothesis is $\tau_{2}$ and $\tau_{3}$ are not all $0$. Under $\alpha = 0.01$, the critical value $F(\alpha;2,6597)=4.61$, which is less than F ratio $52.56$. Therefore, we reject null hypothesis, and there is a significant association between `star1` and `math1`.

### Model Diagnostic

Recalling the above assumptions, we need to check the normality of the residuals to make sure that our model is reasonable.
We start to check the assumption that $E(\epsilon_{ij})=0$ and $\epsilon_{ij}$ are normally distributed. 
From the scatter plot of residuals vs fitted values, the residuals are divided into three groups and among each group, these residuals are around the zero, which means that the average residuals almost equals to zero.
According to the histogram of residuals and studentized residuals, we can find that the distribution of the residuals of the fitted model approximates to the normal distribution. Besides, the same conclusion can be obtained by checking the Q-Q Plot of the residuals. Therefore, we can confirm that the residuals of the model are normally distributed.

Then, we turn to formal tests of the equality of variances.
First, we calculate the variances for each type of class and find that the variances of three types of class are close to each other.

|Variances of three types|
|------|------|------|
|regular|small|regular+aide|
| 1734.825  | 1945.082  | 1837.493 |
| |
Then, because the sample sizes of the three types of class are not the same, we choose two formal tests, which are Bartlett test and Levene test, to check the equality of model variances.

Bartlett's test is used to test the null hypothesis, $H_0$ that all k population variances are equal against the alternative $H_a$ that at least two are different.
If there are k samples with sizes $n_i$ and sample variances $S_i^2$ then Bartlett's test statistic is  

$\chi ^{2}={\frac  {(N-k)\ln(S_{p}^{2})-\sum _{{i=1}}^{k}(n_{i}-1)\ln(S_{i}^{2})}{1+{\frac  {1}{3(k-1)}}\left(\sum _{{i=1}}^{k}({\frac  {1}{n_{i}-1}})-{\frac  {1}{N-k}}\right)}}$
where ${\displaystyle N=\sum _{i=1}^{k}n_{i}}$ and ${\displaystyle S_{p}^{2}={\frac {1}{N-k}}\sum _{i}(n_{i}-1)S_{i}^{2}}$ is the pooled estimate for the variance.

The test statistic has approximately a ${\displaystyle \chi _{k-1}^{2}}$ distribution. Thus the null hypothesis is rejected if ${\displaystyle \chi ^{2}>\chi _{k-1,\alpha }^{2}}$ (where ${\displaystyle \chi _{k-1,\alpha }^{2}}$ is the upper tail critical value for the ${\displaystyle \chi _{k-1}^{2}}$ distribution).

|Bartlett test of homogeneity of variances|
| ------------|------|------|
|$\chi^2$ = 2.3004 | df = 2 | p-value = 0.3166 |
| |
The null hypothesis $H_0$ of Levene's test is that all k population variances are equal against the alternative $H_a$ that at least two are different. It is equivalent to a 1-way between-groups analysis of variance (ANOVA) with the dependent variable being the absolute value of the difference between a score and the mean of the group to which the score belongs (shown below as ${\displaystyle Z_{ij}=|Y_{ij}-{\bar {Y}}_{i\cdot }|}$). The test statistic, ${\displaystyle W}$, is equivalent to the ${\displaystyle F}$ statistic that would be produced by such an ANOVA, and is defined as follows:

${\displaystyle W={\frac {(N-k)}{(k-1)}}\cdot {\frac {\sum _{i=1}^{k}N_{i}(Z_{i\cdot }-Z_{\cdot \cdot })^{2}}{\sum _{i=1}^{k}\sum _{j=1}^{N_{i}}(Z_{ij}-Z_{i\cdot })^{2}}},}$

The test statistic ${\displaystyle W}$ is approximately F-distributed with ${\displaystyle k-1}$ and ${\displaystyle N-k}$ degrees of freedom, so the null hypothesis is rejected if ${\displaystyle W >F(k-1,N-k;1-\alpha)}$

| Levene's Test for Homogeneity of Variance (center = median) |
| ------------- |----|----|----|
|     | Df    | F value | Pr(>F) |
|group | 2   | 1.1836 | 0.3062 |
|     | 6597 |                 |
| |
From the results of the two tests, both of the P-values are much larger than 0.05, which means that we can not reject the null hypothesis: the variances of the model are equal.

In conclusion, we confirm that our model satisfies the normality assumption that $\epsilon_{ij}\sim\mathrm{N}(0,\sigma^{2})$.





###Difference among factors

In order to investigate whether there is a difference among three factor level means, We choose to use F-test. Moreover, to investigate comparisons between every two factor level means simultaneously and control the family wise error rate, we use Tukey’s Procedure and Bonferroni’s Procedure.

####F-test  

To test null hypotheis $H_0:\mu_1=\mu_2=\mu_3$ against alternative hypothesis: not all $\mu_{i}$'s are equal. We caculate F-statistic: $F^*=\frac{MSTR}{MSE}=52.16923$ and $F(0.95,2,6597)=2.997093$. Because $F^*>F(0.95,2,6597)$, We can reject the null hypothesis at the significance level 0.05. We can claim that there exists difference among factor level means.

####Tukey’s Procedure 

For Tukey's Procedure, the largest difference is between small and regular, it is e^0.025 = 1.02. All the p values are less than 0.05, every two factors are statistically significant. 

####Bonferroni’s Procedure

For Bonfeeoni's Procedure, all of p values of three pairwise comparison is less than 0.05. We can make a conclusion that every two factors are statistically significant. We get the same result as Tukey's Procedure. 

###Causal statements

We will investigate whether there are any causal statements of math grade in three different class types. Instead of discussing all of them simultaneously, our strategy is to make pairwise tests among them. Therefore, we will take three tests including small class with regular class, small class with regular-with-aid class and regular class with regular-with-aid class.

In our causal inference, potential outcome is the "math1", which represents the math grade in 1st grade. And there are three assumptions, it should satisfy:  
1.Causal order can't be reversed.  
2.No spillover effect.  
3.same version of treatment.  
4.potential outcomes follow a normal distribution.  
All of them are satisfied, then, causal inference can start.

For a causal effect test:  
Null hypothese $H_0: Y_{i}(1) = Y_{i}(0)$ for all $i=1,2,3,\cdots,N$.  
Alternative hypothese $H_{a}:$ not for all $i$, $Y_{i}(1) = Y_{i}(0)$,  
where $Y_{i}(1)$ represents the $i$-th potential outcome when $Z_{i}=1$; $Y_{i}(0)$ represents the $i$-th potential outcome when $Z_{i}=0$. $Z_{i}=1$ and $Z_{i}=0$ stand for different treatments and $N$ represents the total number of potential outcomes.

Our estimand is $\tau \equiv  \overline{Y(1)}-\overline{Y(0)}$. The unbiased estimator of this estimand is $\hat{\tau} = \frac{\sum_{i}^{N}1\{Z_{i}=1\}Y_{i}(1)}{N_{1}}-\frac{\sum_{i}^{N}1\{Z_{i}=0\}Y_{i}(0)}{N_{0}}$, where $N_{1}$ represnets the number of observed outcomes when $Z_{i}=1$ and $N_{0}$ represnets the number of observed outcomes when $Z_{i}=0$. It also has $N_{1}+N_{0}=N$.  
The true variance of $\hat{\tau}$ is $\frac{S_{1}^{2}}{N_{1}}+\frac{S_{0}^{2}}{N_{0}}-\frac{S_{10}^{2}}{N_{}}$, where $S_{1}^{2}=\frac{1}{N-1}\sum_{i=1}^N(Y_i(1)-\bar Y(1))^2$, $S_{0}^{2}=\frac{1}{N-1}\sum_{i=1}^N(Y_i(0)-\bar Y(0))^2$, $S_{10}^{2}=\frac{1}{N-1}\sum_{i=1}^N((Y_i(0)-Y_i(0))-(\bar Y(1)-\bar Y(0)))^2$. It is worthy to note that, $S_{10}^{2}$ equals to zero if the treatment effect is
constant for all $i$. Therefore, our estimator of variance is $\widehat{var}(\hat\tau)= \frac{S_{1}^{2}}{N_{1}}+\frac{S_{0}^{2}}{N_{0}}$.  
Then we get a statistic $t^*=\frac{\hat{\tau}}{\widehat{var}(\hat\tau)}$. And it approximately follows the t-distribution. For the degree of freedom, we take the	Welch's approximate t solution to estimate it [1] (https://en.m.wikipedia.org/wiki/Behrens%E2%80%93Fisher_problem). The degree of freedom $\upsilon$ can be regarded as $\frac{(\gamma_1+\gamma_2)^2}{\gamma_1^2/(n_1-1)+\gamma_2^2/(n_2-1)}$, where $\gamma_i=\frac{\sigma_2^2}{n_i}$. For the significance level $\alpha$, because we do pairwise tests, let $\alpha=1-0.05/3$ as the significance level to control the family wise error rate. Compared with two values, we can make a conclusion whether there is a casual effect.
Test 1  
Treatments: small class type, regular class type.  
$t^*=\frac{\hat{\tau}}{\widehat{var}(\hat\tau)}=8.077159$, degree of freedom $\upsilon\approx3892$. And $t^*>t(1-0.05/3,3892)$. We reject the null hypothese and make a claim that there is a casual effect, that is, compared with regular class, small class contributes to higher math grade in 1st grade.
Test 2  
Treatments: small class type, regular-with-aide class type.  
$t^*=\frac{\hat{\tau}}{\widehat{var}(\hat\tau)}=4.820985$, degree of freedom $\upsilon\approx 3928$. And $t^*>t(1-0.05/3,3928)$. We reject the null hypothese and make a claim that there is a casual effect, that is, compared with regular-with-aide class, small class contributes to higher math grade in 1st grade.  
Test 3  
Treatments: regular class type, regular-with-aide class type.  
$t^*=\frac{\hat{\tau}}{\widehat{var}(\hat\tau)}=3.294502$, degree of freedom $\upsilon\approx 4628$. And $t^*>t(1-0.05/3,4628)$. We reject the null hypothese and make a claim that there is a casual effect, that is, compared with regular-with-aide class, regular class contributes to higher math grade in 1st grade.  
We can make a conclusion that there are causal effects among pairwise comparisons.



# Conclusions and Discussion




# References

[1] https://chenshizhe.github.io/STA207W2020/ch-proj.html#project-1-project-star-i

[2] https://cran.r-project.org/web/packages/AER/AER.pdf



# Code and Output


