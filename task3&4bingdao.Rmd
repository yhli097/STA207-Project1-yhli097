---
title: "task3-5"
output: html_document
---
---
title: "Project1"
author: "Yahui Li"
date: "2020/1/13"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Step1 Read Data

```{r read data, echo = FALSE, message = FALSE}
#install.packages("AER")
library(AER)
data("STAR")
```

###Step2 Explore Data
We will only examine the math scores in 1st grade in this project.
```{r}
data <- data.frame(star1 = STAR$star1, math1 = STAR$math1)
sapply(data,class)
sapply(data,summary)
```

```{r}
data_remove_na <- na.omit(data[-is.na(data$star1),])
```


###Step3 One Way ANOVA Model


Task3:Write down a one-way ANOVA model to study the effects of class types on the math scaled scores. Explain your notation.


$$Y_{ij} = \mu_{1} + \tau_{2}X_{2,ij} +\tau_{3}X_{3,ij}+\epsilon_{ij},\quad
\epsilon_{ij}\sim\mathrm{N}(0,\sigma^{2}),\quad
i=1,2,3,j=1,\cdots,n_{i}.$$


where $i=1$ means the class type in 1st grade is regular; $i=2$ means the class type in 1 st grade is small; $i=3$ means the class type in 1st grade is regular-with-aide.

From the table in step2, $n_{1} = 2507, n_{2} = 1868, n_{3} = 2225, n = 6600$, they represent the number of experimental units in the $i$-th treatment group respectively.

$Y_{ij}$ denotes the math grade in 1st grade of the $j$-th experimental unit
in the $i$-th class type.

$\mu_{i}$ means the population mean of the i-th type class in 1st grade, $i = 1, 2, 3$.

$\tau_{i} = \mu_{i} - \mu_{1}$ means the difference in population mean between i-th type and first type in 1st grade, $i = 2, 3$.

$\epsilon_{ij}$ is the random variable and assumed to be i.i.d. Normal(0,$\sigma^{2}$).  

Model Assumption  
(a) Response variable residuals are normally distributed.  
(b) Variances of populations are equal.  
(c) Responses for a given group are independent and identically distributed normal random variables.  
All of the assumptions are necessary, because for each population violate the normal distribution, F-tests are not robust. Moreover, if the assumption of homoscedasticity is violated, the Type I error properties degenerate much more severely.[5] ( Randolf, E. A.; Barcikowski, R. S. (1989). "Type I error rate when real study values are used as population parameters in a Monte Carlo study". Paper presented at the 11th annual meeting of the Mid-Western Educational Research Association, Chicago.)  

###Task4  
Task4: Explain why your model is appropriate for this task on this data set. You may want to include statistics and plots in your explanation.

Before we fit the model, we need to ensure that model is appropriate on this dataset, that is, the response variable satisfies the assumptions of our model. In other words, we will check the normality and equal variance of the response varibales.

We first make a boxcox plot to find whether a transformation is necessary.
```{r}
library(MASS)
boxcox(math1 ~ star1 , data = data_remove_na)
```
This plot indicates that we need a log-transformation for "math1".
```{r}
data_log <- data.frame(star1 = data_remove_na$star1, logmath1 = log(data_remove_na$math1))
```

Then we will make a density plot and a Q-Q plot to check the normality of "log-math1"

```{r}
library(ggplot2)
summary(data_log$logmath1)
x <- seq(6.001, 6.516, length.out=100)
df <- with(data_log, data.frame(x = x, y = dnorm(x, mean(logmath1), sd(logmath1))))

ggplot(data_log, aes(x=logmath1, y = ..density..)) + 
  geom_histogram(binwidth = 0.01, fill = "grey", color = "black") +
  geom_line(data = df, aes(x = x, y = y), color = "red")
```

As we can see, the distribution of "math1" is nearly normalized.

```{r}
qqnorm(data_log$logmath1, pch = 1, frame = FALSE)
qqline(data_log$logmath1, col = "steelblue", lwd = 2)
```
From the Q-Q plot, we can see that it is slightly light-tailed and it is neaely a straight line.

Then we calculate the variance of math grade in 1st grade of each class type.
```{r}
library(tidyverse)
data_log %>%
  group_by(star1) %>%
  summarize(var_math1 = var(logmath1, na.rm = T))
```
The result shows that they are nearly equal. Therefore, it is appropiate to run our model on this dataset.
